{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-17T20:36:28.967893Z","iopub.execute_input":"2022-10-17T20:36:28.968351Z","iopub.status.idle":"2022-10-17T20:36:28.978964Z","shell.execute_reply.started":"2022-10-17T20:36:28.968310Z","shell.execute_reply":"2022-10-17T20:36:28.977468Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/dogs-vs-cats/test1.zip\n/kaggle/input/dogs-vs-cats/train.zip\n/kaggle/input/dogs-vs-cats/sampleSubmission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!wget --no-check-certificate https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:36:28.983098Z","iopub.execute_input":"2022-10-17T20:36:28.983701Z","iopub.status.idle":"2022-10-17T20:36:30.575395Z","shell.execute_reply.started":"2022-10-17T20:36:28.983660Z","shell.execute_reply":"2022-10-17T20:36:30.574213Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"--2022-10-17 20:36:29--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 173.194.216.128, 74.125.26.128, 173.194.215.128, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|173.194.216.128|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 68606236 (65M) [application/zip]\nSaving to: ‘cats_and_dogs_filtered.zip’\n\ncats_and_dogs_filte 100%[===================>]  65.43M   171MB/s    in 0.4s    \n\n2022-10-17 20:36:30 (171 MB/s) - ‘cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import zipfile\n\ndata = zipfile.ZipFile('./cats_and_dogs_filtered.zip','r')\ndata.extractall()\ndata.close()","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:36:30.578403Z","iopub.execute_input":"2022-10-17T20:36:30.579676Z","iopub.status.idle":"2022-10-17T20:36:31.688877Z","shell.execute_reply.started":"2022-10-17T20:36:30.579626Z","shell.execute_reply":"2022-10-17T20:36:31.687221Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# check content of train folder\nimport os\nprint(\"Contents of this folder are:\")\nprint(os.listdir('cats_and_dogs_filtered'))","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:36:31.690589Z","iopub.execute_input":"2022-10-17T20:36:31.691127Z","iopub.status.idle":"2022-10-17T20:36:31.698959Z","shell.execute_reply.started":"2022-10-17T20:36:31.691016Z","shell.execute_reply":"2022-10-17T20:36:31.697600Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Contents of this folder are:\n['validation', 'vectorize.py', 'train']\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_gen = ImageDataGenerator(rescale = 1.0/255)\ntrain_data = train_gen.flow_from_directory('cats_and_dogs_filtered/train',target_size = (200,200),class_mode='binary',batch_size = 32)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:36:31.701818Z","iopub.execute_input":"2022-10-17T20:36:31.702284Z","iopub.status.idle":"2022-10-17T20:36:31.817777Z","shell.execute_reply.started":"2022-10-17T20:36:31.702240Z","shell.execute_reply":"2022-10-17T20:36:31.816371Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 2000 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"valid_gen = ImageDataGenerator(rescale = 1.0/255)\nvalid_data = valid_gen.flow_from_directory('cats_and_dogs_filtered/validation',target_size = (200,200),class_mode='binary',batch_size = 32)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:36:31.819140Z","iopub.execute_input":"2022-10-17T20:36:31.819537Z","iopub.status.idle":"2022-10-17T20:36:31.929385Z","shell.execute_reply.started":"2022-10-17T20:36:31.819501Z","shell.execute_reply":"2022-10-17T20:36:31.928308Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Found 1000 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nmodel = Sequential()","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:36:31.931053Z","iopub.execute_input":"2022-10-17T20:36:31.931413Z","iopub.status.idle":"2022-10-17T20:36:32.003491Z","shell.execute_reply.started":"2022-10-17T20:36:31.931382Z","shell.execute_reply":"2022-10-17T20:36:32.002475Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2022-10-17 20:36:31.976329: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, Dropout\nmodel.add(Conv2D(20,(3,3),activation='relu',input_shape = (200,200,3)))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(40,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(80,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Flatten())\nmodel.add(Dense(250,activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(150,activation = 'relu'))\nmodel.add(Dense(50,activation = 'relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1,activation = 'sigmoid'))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:36:32.004625Z","iopub.execute_input":"2022-10-17T20:36:32.005425Z","iopub.status.idle":"2022-10-17T20:36:32.479091Z","shell.execute_reply.started":"2022-10-17T20:36:32.005387Z","shell.execute_reply":"2022-10-17T20:36:32.477665Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 198, 198, 20)      560       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 99, 99, 20)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 97, 97, 40)        7240      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 48, 48, 40)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 46, 46, 80)        28880     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 23, 23, 80)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 42320)             0         \n_________________________________________________________________\ndense (Dense)                (None, 250)               10580250  \n_________________________________________________________________\ndropout (Dropout)            (None, 250)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 150)               37650     \n_________________________________________________________________\ndense_2 (Dense)              (None, 50)                7550      \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 50)                0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 51        \n=================================================================\nTotal params: 10,662,181\nTrainable params: 10,662,181\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:36:32.480683Z","iopub.execute_input":"2022-10-17T20:36:32.481398Z","iopub.status.idle":"2022-10-17T20:36:32.496665Z","shell.execute_reply.started":"2022-10-17T20:36:32.481357Z","shell.execute_reply":"2022-10-17T20:36:32.495191Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint,EarlyStopping\nstop = EarlyStopping(patience=20)\ncheck = ModelCheckpoint('best_model.hdf5',monitor='val_loss',save_best_only=True)\nmodel.fit(train_data,epochs=20,callbacks=[stop,check],validation_data=valid_data)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:36:32.498384Z","iopub.execute_input":"2022-10-17T20:36:32.498866Z","iopub.status.idle":"2022-10-17T20:36:40.867790Z","shell.execute_reply.started":"2022-10-17T20:36:32.498819Z","shell.execute_reply":"2022-10-17T20:36:40.865436Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"2022-10-17 20:36:32.740535: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n11/63 [====>.........................] - ETA: 28s - loss: 0.7226 - accuracy: 0.5057","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_18/1423056139.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport random\nfrom tensorflow.keras.preprocessing.image import img_to_array , load_img\n\nsuccessive_output = [layer.output for layer in model.layers]\nvisual_model = tf.keras.models.Model(inputs = model.input, outputs = successive_output)\nimg_path = 'cats_and_dogs_filtered/validation/dogs/dog.2140.jpg'\nimg = load_img(img_path,target_size=(200,200))\nx = img_to_array(img)\nx = x.reshape((1,) + x.shape)\nx/= 255\nsuccessive_feature_maps = visual_model.predict(x)\n\n# These are the names of the layers, so you can have them as part of our plot\nlayer_names = [layer.name for layer in model.layers]\n\n# Display the representations\nfor layer_name, feature_map in zip(layer_names, successive_feature_maps):\n  \n  if len(feature_map.shape) == 4:\n    \n    #-------------------------------------------\n    # Just do this for the conv / maxpool layers, not the fully-connected layers\n    #-------------------------------------------\n    n_features = feature_map.shape[-1]  # number of features in the feature map\n    size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n    \n    # Tile the images in this matrix\n    display_grid = np.zeros((size, size * n_features))\n    \n    #-------------------------------------------------\n    # Postprocess the feature to be visually palatable\n    #-------------------------------------------------\n    for i in range(n_features):\n      x  = feature_map[0, :, :, i]\n      x -= x.mean()\n      x /= x.std ()\n      x *=  64\n      x += 128\n      x  = np.clip(x, 0, 255).astype('uint8')\n      display_grid[:, i * size : (i + 1) * size] = x # Tile each filter into a horizontal grid\n\n    #-----------------\n    # Display the grid\n    #-----------------\n    scale = 20. / n_features\n    plt.figure( figsize=(scale * n_features, scale) )\n    plt.title ( layer_name )\n    plt.grid  ( False )\n    plt.imshow( display_grid, aspect='auto', cmap='viridis' ) ","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:36:40.869016Z","iopub.status.idle":"2022-10-17T20:36:40.869672Z","shell.execute_reply.started":"2022-10-17T20:36:40.869470Z","shell.execute_reply":"2022-10-17T20:36:40.869492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}